{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "raw_data = loadarff('breast.w.arff')\n",
    "df_data = pd.DataFrame(raw_data[0])  # converting data to a pandas DataFrame\n",
    "df_data = df_data.dropna()  # all rows with Na values are dropped\n",
    "df_data['Class'].replace({b'malignant': 1, b'benign': 0}, inplace=True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-conditional distributions per variable using a 3x3 plot grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Drawing the plots -------------------------------------\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "for idx, variable in enumerate(df_data.drop(columns='Class')):\n",
    "    # A 3x3 plot grid is created and subplots are placed\n",
    "    sub = fig.add_subplot(3, 3, idx+1)\n",
    "    sub.set_xlabel(variable)\n",
    "    # data is separated by class and plots are overlaid\n",
    "    sub.hist(df_data[variable].loc[df_data['Class'] == 0], color=\"c\")\n",
    "    sub.hist(df_data[variable].loc[df_data['Class'] == 1],\n",
    "             color=\"firebrick\", alpha=0.5)\n",
    "\n",
    "fig.legend(labels=[\"Benign\", \"Malign\"], loc=\"upper right\", fontsize=15)\n",
    "plt.savefig('plots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN cross validation : Finding the best K value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns except for the class column\n",
    "data = df_data.drop(columns=['Class']).values\n",
    "target = df_data['Class'].values  # target column is the class column\n",
    "\n",
    "for k in range(3, 8, 2):  # data is split with a 10-fold cv and used for training and testing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights=\"uniform\", p=2)\n",
    "    # random_state = seed = 10\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=10)\n",
    "    accuracies = []\n",
    "    for train_subset, test_subset in kf.split(data):\n",
    "        X_train, X_test = data[train_subset], data[test_subset]\n",
    "        Y_train, Y_test = target[train_subset], target[test_subset]\n",
    "        knn.fit(X_train, Y_train)  # train\n",
    "        accuracies.append(knn.score(X_test, Y_test))  # test and store accuracy\n",
    "    print(\"Accuracy with K = \" + str(k) + \" \" +\n",
    "          str(np.mean(accuracies)))  # accuracy mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", p=2)\n",
    "naive_bayes = MultinomialNB()\n",
    "knn_acc, bayes_acc = [], []  # accuracies for each set and for each classifier\n",
    "\n",
    "for train_subset, test_subset in kf.split(data):\n",
    "    X_train, X_test = data[train_subset], data[test_subset]\n",
    "    Y_train, Y_test = target[train_subset], target[test_subset]\n",
    "    knn.fit(X_train, Y_train)  # train\n",
    "    naive_bayes.fit(X_train, Y_train)\n",
    "    knn_acc.append(knn.score(X_test, Y_test))  # test and store accuracy\n",
    "    bayes_acc.append(naive_bayes.score(X_test, Y_test))\n",
    "\n",
    "t_value, pvalue = stats.ttest_rel(knn_acc, bayes_acc)  # t-test\n",
    "if pvalue <= 0.05:\n",
    "    print('The alternative hypotesis : \"𝑘NN is statistically superior to Naïve Bayes\" is confirmed')\n",
    "else:\n",
    "    print('The null hypotesis : \"𝑘NN is statistically equal to Naïve Bayes\" is confirmed')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
